---
title: "More advanced optim example"
output: html_document
author: Peter Scully
date: "2024-06-03"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup
First, we need to import the relevant libraries:
```{r imports}
library(ggplot2)
```

## Objective Function

Let's start by creating the objective function we want to minimize.

Our goal is to minimize the MSE between our predicted y-values and the actual
y-values.
```{r obj_fxn}
# Note: This function is based heavily on the function from the first 
#       optimization exercise

# objective_function: measures residual sum of squares between predictions for
#                     given parameters and actual y-data
# Args: 
#   data: data.frame containing an x and y column 
#   par: numeric vector of three parameters for the polynomial used to make 
#        predictions
# Returns: numeric vector length 1 containing the MSE between predicted and
#          observed y
objective_function <- function(data, par) {
  
  predicted_y <- par[1] + par[2] * data$x + par[3] * (data$x)^2
  SE <- (predicted_y - data$y)^2
  MSE <- mean(SE)
  return(MSE)
  
}
```


## Getting Data
Now we need to get the data we want to fit from our csv. Let's also plot it
so we have an idea of what we're looking at:
```{r read_data}
data <- read.csv(file.path(here::here(), '02', 'example_data.csv'))
ggplot() + geom_point(data = data, aes(x = x, y = y))
```

## Using optim
Now, let's call optim to find the optimal parameters for fitting this function
```{r optim_call}
optim_output <- optim(par = c(0, 0, 0.75),
                      fn = objective_function,
                      data = data)
best_pars <- optim_output$par
```

Based on optim's output, it seems that the best fit for the model is: $y = `r round(best_pars[1], 3)` + `r round(best_pars[2], 3)`x + `r round(best_pars[3], 3)`x^2$. 

## Evaluating the Fit

Let's see how this fit looks when plotted
```{r plotting}
# Before plotting, we need to get all the data to plot
# Let's start by getting the predicted y values
pred_data <- data.frame(data$x)
colnames(pred_data) <- "x"
pred_data$y <- best_pars[1] + 
               best_pars[2] * pred_data$x + 
               best_pars[3] * (pred_data$x)^2

# Now let's make our plot:
ggplot() + 
  geom_point(data = data, aes(x = x, y = y)) +
  geom_line(data = pred_data, aes(x = x, y = y))

```

This fit looks quite reasonable, but let's see what the RMSE is between the fitted model and the observed data:
```{r rmse}
# To calculate the RMSE, we just need to take the square root of the value of 
# our objective function for our best fit, since our objective function finds 
# the MSE between predicted and observed data
rmse <- sqrt(optim_output$value)
rmse
```

Looking back at our graph, it seems that most of this error is coming from variability within the data itself rather than from an issue with our fit.

We can also evaluate our fit by examining the residuals:
```{r residuals}
# Before plotting, we need to actually calculate the residuals
pred_data$residuals <- data$y - pred_data$y

# Now let's make our plot:
ggplot() + 
  geom_point(data = pred_data, aes(x = x, y = residuals)) +
  ggtitle("Residual Plot")

```

There does not appear to be any trend in the residuals (which would indicate a likely issue with our fit).

## Comparison with the Actual Model
As noted above, optim found that the best fit for the observations is: $y = `r round(best_pars[1], 3)` + `r round(best_pars[2], 3)`x + `r round(best_pars[3], 3)`x^2$. 

However, the actual model used to generate this data set is: $y = 3 + 2.5x + 0.5x^2$. Although my quadratic coefficient lines up closely with the actual coefficient, my linear coefficient is off by more than 0.2 and my constant term is off by more than 5. These errors don't seem super large given how much variability is in the observational record to begin with but they are still notable. I think a lot of these differences could be simply due to chance, with the random sampling of data points having a slightly lower average value than the actual model.

Ultimately, given that there didn't seem to be any trend in the residuals and that, considering the variability within the observations themselves, my best fit quite close to the actual model, I am not very concerned about my parameter estimates.
